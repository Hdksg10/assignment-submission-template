# ç®—å­è§„æ ¼è¯´æ˜

## ç®—å­åˆ†ç±»

### æ•°å€¼é¢„å¤„ç† (Numerical Preprocessing)

#### StandardScaler
- **åŠŸèƒ½**: æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾ (z-scoreæ ‡å‡†åŒ–)
- **è¾“å…¥**: æ•°å€¼åˆ—
- **è¾“å‡º**: æ ‡å‡†åŒ–åçš„æ•°å€¼åˆ—
- **å‚æ•°**:
  - `with_mean`: æ˜¯å¦ä¸­å¿ƒåŒ– (é»˜è®¤: True)
  - `with_std`: æ˜¯å¦æ ‡å‡†åŒ– (é»˜è®¤: True)
- **Sparkå®ç°**: `StandardScaler`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + scikit-learn

#### MinMaxScaler
- **åŠŸèƒ½**: æœ€å°æœ€å¤§æ ‡å‡†åŒ–
- **è¾“å…¥**: æ•°å€¼åˆ—
- **è¾“å‡º**: [0,1]èŒƒå›´å†…çš„æ•°å€¼åˆ—
- **å‚æ•°**:
  - `min`: æœ€å°å€¼ (é»˜è®¤: 0.0)
  - `max`: æœ€å¤§å€¼ (é»˜è®¤: 1.0)
- **Sparkå®ç°**: `MinMaxScaler`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + scikit-learn

#### Imputer
- **åŠŸèƒ½**: ç¼ºå¤±å€¼å¡«å……
- **è¾“å…¥**: åŒ…å«ç¼ºå¤±å€¼çš„æ•°å€¼åˆ—
- **è¾“å‡º**: å¡«å……åçš„æ•°å€¼åˆ—
- **å‚æ•°**:
  - `strategy`: å¡«å……ç­–ç•¥ ('mean', 'median', 'most_frequent', 'constant')
  - `fill_value`: å¸¸é‡å¡«å……å€¼ (å½“strategy='constant'æ—¶)
- **Sparkå®ç°**: `Imputer`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + pandas/scikit-learn

### ç±»åˆ«é¢„å¤„ç† (Categorical Preprocessing)

#### StringIndexer
- **åŠŸèƒ½**: å­—ç¬¦ä¸²åˆ°æ•°å­—çš„æ˜ å°„
- **è¾“å…¥**: ç±»åˆ«å­—ç¬¦ä¸²åˆ—
- **è¾“å‡º**: æ•°å­—ç¼–ç åˆ—
- **å‚æ•°**:
  - `handle_invalid`: æ— æ•ˆå€¼çš„å¤„ç†æ–¹å¼ ('error', 'skip', 'keep')
- **Sparkå®ç°**: `StringIndexer`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + sklearn.preprocessing.LabelEncoder

#### OneHotEncoder
- **åŠŸèƒ½**: ç‹¬çƒ­ç¼–ç 
- **è¾“å…¥**: æ•°å­—ç¼–ç åˆ—
- **è¾“å‡º**: ç‹¬çƒ­ç¼–ç çš„å¤šåˆ—
- **å‚æ•°**:
  - `drop_last`: æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€åˆ—é¿å…å¤šé‡å…±çº¿æ€§ (é»˜è®¤: True)
- **Sparkå®ç°**: `OneHotEncoder`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + sklearn.preprocessing.OneHotEncoder

### æ–‡æœ¬é¢„å¤„ç† (Text Preprocessing)

#### Tokenizer
- **åŠŸèƒ½**: æ–‡æœ¬åˆ†è¯
- **è¾“å…¥**: æ–‡æœ¬å­—ç¬¦ä¸²åˆ—
- **è¾“å‡º**: åˆ†è¯åçš„æ•°ç»„åˆ—
- **å‚æ•°**:
  - `pattern`: åˆ†è¯æ¨¡å¼ (æ­£åˆ™è¡¨è¾¾å¼)
- **Sparkå®ç°**: `Tokenizer`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + NLTKæˆ–è‡ªå®šä¹‰åˆ†è¯å™¨

#### HashingTF
- **åŠŸèƒ½**: ç‰¹å¾å“ˆå¸Œå‘é‡åŒ–
- **è¾“å…¥**: è¯æ±‡æ•°ç»„åˆ—
- **è¾“å‡º**: å“ˆå¸Œç‰¹å¾å‘é‡
- **å‚æ•°**:
  - `num_features`: ç‰¹å¾ç»´åº¦ (é»˜è®¤: 2^18)
- **Sparkå®ç°**: `HashingTF`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + sklearn.feature_extraction.text.HashingVectorizer

#### IDF (Inverse Document Frequency)
- **åŠŸèƒ½**: é€†æ–‡æ¡£é¢‘ç‡è½¬æ¢
- **è¾“å…¥**: è¯é¢‘å‘é‡åˆ—
- **è¾“å‡º**: TF-IDFå‘é‡
- **å‚æ•°**:
  - `min_doc_freq`: æœ€å°æ–‡æ¡£é¢‘ç‡ (é»˜è®¤: 1)
- **Sparkå®ç°**: `IDF`
- **Rayå®ç°**: ä½¿ç”¨Ray Data map_batches + sklearn.feature_extraction.text.TfidfTransformer

## å®ç°çŠ¶æ€

### å·²å®ç°ç®—å­
- âœ… StandardScaler (Spark + Ray)

### å¼€å‘ä¸­ç®—å­
- ğŸ”„ StringIndexer (è®¡åˆ’ä¸­)
- ğŸ”„ OneHotEncoder (è®¡åˆ’ä¸­)

### å¾…å®ç°ç®—å­
- â³ MinMaxScaler
- â³ Imputer
- â³ Tokenizer
- â³ HashingTF
- â³ IDF

## ç®—å­è§„æ ¼å®šä¹‰

æ¯ä¸ªç®—å­éœ€è¦å®šä¹‰ä»¥ä¸‹è§„æ ¼ï¼š

```python
OperatorSpec(
    name="StandardScaler",
    input_cols=["feature1", "feature2"],
    output_cols=["feature1_scaled", "feature2_scaled"],
    params={
        "with_mean": True,
        "with_std": True
    },
    description="Standardize features by removing the mean and scaling to unit variance"
)
```

## æ·»åŠ æ–°ç®—å­æµç¨‹

1. **å®šä¹‰è§„æ ¼**: åœ¨ `src/bench/operator_spec.py` ä¸­æ·»åŠ ç®—å­è§„æ ¼
2. **Sparkå®ç°**: åœ¨ `src/engines/spark/operators/` ä¸­å®ç°å¯¹åº”å‡½æ•°
3. **Rayå®ç°**: åœ¨ `src/engines/ray/operators/` ä¸­å®ç°å¯¹åº”å‡½æ•°
4. **æ›´æ–°æ–‡æ¡£**: åœ¨æœ¬æ–‡æ¡£ä¸­æ·»åŠ ç®—å­è¯´æ˜
5. **æ·»åŠ æµ‹è¯•**: åœ¨ `tests/` ä¸­æ·»åŠ ç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹
6. **éªŒè¯ä¸€è‡´æ€§**: ç¡®ä¿ä¸¤ä¸ªå¼•æ“è¾“å‡ºç»“æœçš„ä¸€è‡´æ€§
