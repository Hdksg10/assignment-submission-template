# 设计原则

## 整体架构

本项目采用分层架构设计，确保Spark MLlib与Ray生态在预处理算子上的公平对比：

```
┌─────────────────┐
│   CLI & Metrics │  ← 统一接口层
├─────────────────┤
│ Operator Specs  │  ← 引擎无关层
├─────────────────┤
│  Spark Engine   │  ← 引擎适配层
│  Ray Engine     │
└─────────────────┘
```

## 统一原则

### 引擎无关层

- **算子规格**: 定义算子的输入输出Schema、参数规范，与具体引擎实现解耦
- **数据IO**: 统一的数据加载和保存接口，支持CSV、Parquet等格式
- **指标采集**: 标准化性能指标收集，包括耗时、吞吐量等
- **CLI接口**: 统一的命令行接口，支持单引擎运行和对比测试

### 引擎适配层

- **Spark**: 使用Spark MLlib的标准算子实现
- **Ray**: 使用Ray Data/Ray Train生态实现等价功能
- **接口一致性**: 各引擎实现相同的算子接口规范

## 对比口径

### 数据一致性
- **输入数据**: 使用相同的CSV/Parquet数据集
- **数据类型**: 确保各引擎正确识别和处理数据类型
- **数据规模**: 在相同数据量级下进行对比

### 参数等价性
- **算子参数**: 使用尽可能等价的参数配置
- **默认值**: 遵循各框架的合理默认值
- **可配置性**: 支持通过配置文件调整参数

### 输出对齐
- **Schema一致性**: 输出DataFrame的列名、类型应保持一致
- **数据完整性**: 行数、关键统计量应匹配
- **精度要求**: 数值计算结果在合理误差范围内

## 扩展性设计

### 新算子添加流程
1. 在`operator_spec.py`中定义算子规格
2. 实现Spark版本 (`src/engines/spark/operators/`)
3. 实现Ray版本 (`src/engines/ray/operators/`)
4. 更新文档和测试用例
5. 验证输出一致性

### 新引擎支持
1. 在`src/engines/`下创建新引擎目录
2. 实现算子接口规范
3. 扩展CLI支持
4. 添加相应的测试

## 实验协议

### 性能指标
- **Wall Time**: 总执行时间
- **Throughput**: 每秒处理行数
- **Memory Usage**: 内存使用情况
- **Output Consistency**: 输出一致性校验

### 实验控制
- **重复执行**: 默认3次运行，取平均值和标准差
- **Warm-up**: 预热运行排除JIT影响
- **Isolation**: 各引擎独立运行，避免相互影响

### 结果管理
- **标准化输出**: JSON/CSV格式的结果文件
- **版本追踪**: 记录Git commit和时间戳
- **可复现性**: 配置和环境信息完整记录
